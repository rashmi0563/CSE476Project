
=====================================================================
This module is only for creating or activating Python environments:
$ mamba create -n myenv -c conda-forge python=3 <package_name>
$ source activate myenv

Only run "pip install" after activating an environment.
Running pip without activating an environment is known to cause issues.

To list available environments:
$ mamba info --envs

Other uses are not tested. More info: https://links.asu.edu/solpy
=====================================================================

  
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:12<00:12, 12.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.35s/it]
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
==== previous adapter load complete === : ./llama-3.2-3B-sft
=== Loaded PEFT model's trainable parameter ===
trainable params: 0 || all params: 3,237,063,680 || trainable%: 0.0000
=== Dolly Dataset Train Start ===
  0%|          | 0/1407 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/jpark284/CSE476/train_sft_dolly.py", line 133, in <module>
    trainer.train()
  File "/home/jpark284/.conda/envs/cse476/lib/python3.12/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/jpark284/.conda/envs/cse476/lib/python3.12/site-packages/transformers/trainer.py", line 2560, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpark284/.conda/envs/cse476/lib/python3.12/site-packages/transformers/trainer.py", line 3782, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/home/jpark284/.conda/envs/cse476/lib/python3.12/site-packages/accelerate/accelerator.py", line 2454, in backward
    loss.backward(**kwargs)
  File "/home/jpark284/.local/lib/python3.12/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/home/jpark284/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 289, in backward
    _engine_run_backward(
  File "/home/jpark284/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
  0%|          | 0/1407 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/jpark284/.conda/envs/cse476/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/jpark284/.conda/envs/cse476/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/home/jpark284/.conda/envs/cse476/lib/python3.12/site-packages/accelerate/commands/launch.py", line 1213, in launch_command
    simple_launcher(args)
  File "/home/jpark284/.conda/envs/cse476/lib/python3.12/site-packages/accelerate/commands/launch.py", line 795, in simple_launcher
    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/jpark284/.conda/envs/cse476/bin/python3.12', 'train_sft_dolly.py']' returned non-zero exit status 1.
